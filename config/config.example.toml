# Email categorise / triage configuration
# Copy to config.toml and edit.

[auth]
# auth_mode:
# - "application": daemon / cron friendly (no browser login). Uses client credentials and Graph .default scope.
# - "delegated": interactive login on first use, then cached tokens (requires a browser).
auth_mode = "application"

# Token cache (shared by MSAL). Stored under ./data by default.
token_cache_path = "./data/msal_token_cache.bin"

[azure]
# Public/Confidential app ID (Entra ID App registration -> Application (client) ID)
client_id = "YOUR_CLIENT_ID"

# Default tenant. For single-tenant setups, set this to your tenant GUID.
# For multi-tenant delegated use, "organizations" can work, but for application auth you generally
# want the real tenant ID per org.
tenant_id = "YOUR_TENANT_ID_OR_organizations"

# For application auth, set client secret via env var (do NOT commit secrets).
# The tool reads the secret from this env var name:
client_secret_env = "MS_GRAPH_CLIENT_SECRET"

# Delegated scopes (ONLY used if auth_mode="delegated")
# IMPORTANT: do NOT include openid/profile/offline_access here; MSAL treats them as reserved and will error.
delegated_scopes = [
  "Mail.ReadWrite",
  "Mail.Send"
]

[triage]
lookback_days_initial = 60
lookback_days_incremental = 3
max_messages_per_run = 40

# Body handling (LLM prompt)
# plaintext | html
body_format = "plaintext"
# 0 = unlimited characters; otherwise truncate message body before sending to LLM
body_max_chars = 0
# Limit messages per thread when building context (0 = unlimited)
thread_max_messages = 0

# Tone profiling: Sent Items lookback for building tone profiles
tone_profile_lookback_days = 120

# Features
# These are defaults; per-account overrides are supported under [[accounts]].triage_overrides
draft_replies = false
create_tasks = false
send_summary_email = false
log_to_file = true

# Optional summary email settings (requires Mail.Send)
summary_email_to = "lewis@colemanbros.co.uk"
# Which account should send summaries (must be in [[accounts]])
summary_email_from_account = "lewis@colemanbros.co.uk"

# Per-priority read/unread handling (true = mark read after processing; false = leave unread)
[triage.priority_read_state]
default = false
"Urgent" = false
"Priority 1" = false
"Priority 2" = false
"Priority 3" = false
"Marketing" = true
"Informational" = false
"Complete" = true
"Possibly Complete" = true
"Payment Request" = false
"Invoice" = false
"Order Confirmation" = false
"Issue" = false
"Task" = false

[llm]
# LLM provider for triage + tone profiling + drafting.
#
# provider:
# - "codex": use Codex CLI (recommended). No API key needed if Codex is authenticated already.
# - "codex-oss": use Codex CLI with --oss (routes to local provider, e.g. Ollama).
# - "openai": use the OpenAI API directly (requires `openai` Python package + API key).
# - "openai-compatible": use any OpenAI-compatible HTTP endpoint (local vLLM/TGI/LM Studio/Ollama, etc.).
# - "hf-local": run a local Hugging Face model via `transformers`/`torch` (no HTTP needed).
provider = "codex"

# These are logical model names that point at entries under [models].
# You can swap models by changing these keys without touching the rest of the config.
triage_model = "triage_codex"
reply_model  = "reply_codex"

[models.triage_codex]
provider = "codex"
model = "gpt-5.1-codex-mini"

[models.reply_codex]
provider = "codex"
model = "gpt-5.1-codex-max"

# Example: cheaper/faster Codex-only setup (same model for both triage + replies)
# [models.triage_codex_fast]
# provider = "codex"
# model = "gpt-5.1-codex-mini"
#
# [models.reply_codex_fast]
# provider = "codex"
# model = "gpt-5.1-codex-mini"

# Example: Codex OSS via Ollama (requires Codex CLI `--oss` configured)
# [models.triage_codex_oss]
# provider = "codex-oss"
# model = "llama3.1"
#
# [models.reply_codex_oss]
# provider = "codex-oss"
# model = "llama3.1"

# Example: OpenAI-compatible HTTP endpoint (local vLLM / TGI / LM Studio / Ollama)
# [models.triage_local_http]
# provider = "openai-compatible"
# model = "gpt-4.1-mini"
# base_url = "http://localhost:11434/v1"
# api_key_env = "LOCAL_OPENAI_API_KEY"
#
# [models.reply_local_http]
# provider = "openai-compatible"
# model = "gpt-4.1"
# base_url = "http://localhost:11434/v1"
# api_key_env = "LOCAL_OPENAI_API_KEY"

# Example: Hugging Face local models (loaded via transformers/torch)
# Good starting points for triage / tone profiling (small, fast):
# - microsoft/Phi-3.5-mini-instruct
# - Qwen/Qwen2.5-3B-Instruct
# - mistralai/Mistral-7B-Instruct-v0.3
#
# [models.triage_hf]
# provider = "hf-local"
# model = "microsoft/Phi-3.5-mini-instruct"
# hf_device = "auto"           # "cuda", "cpu", or "auto"
# hf_max_new_tokens = 512
#
# For reply drafting (more nuance, longer outputs), consider:
# - meta-llama/Meta-Llama-3.1-8B-Instruct
# - Qwen/Qwen2.5-7B-Instruct
# - mistralai/Mixtral-8x7B-Instruct-v0.1 (heavier)
#
# [models.reply_hf]
# provider = "hf-local"
# model = "meta-llama/Meta-Llama-3.1-8B-Instruct"
# hf_device = "auto"
# hf_max_new_tokens = 768

# After running a local fine-tune (see `train-finetune` CLI command), you can
# register the resulting model directory as an optional reply model:
#
# [models.reply_finetuned]
# provider = "hf-local"
# model = "/absolute/or/relative/path/to/your/fine_tuned_model_dir"
# hf_device = "auto"
# hf_max_new_tokens = 768

[[accounts]]
email = "lewis@colemanbros.co.uk"
label = "primary"
# Optional override if this mailbox is in a different tenant:
# tenant_id = "YOUR_TENANT_GUID"

# [[accounts]]
# email = "other@another-tenant.com"
# label = "other-org"
# tenant_id = "OTHER_TENANT_GUID"

# Example with per-account overrides:
[[accounts]]
email = "client-mailbox@example.com"
label = "client-org"

# Optional: override tenant/app credentials for this account
[accounts.azure_overrides]
client_id = "CLIENT_APP_ID"
tenant_id = "CLIENT_TENANT_ID"
# If the secret env var differs for this account:
client_secret_env = "CLIENT_MS_GRAPH_SECRET"
# Optional per-account delegated scopes (only if auth_mode=\"delegated\")
# delegated_scopes = ["Mail.ReadWrite", "Mail.Send"]

# Optional: per-account behaviour toggles (fall back to [triage] defaults)
[accounts.triage_overrides]
draft_replies = true
create_tasks = true
send_summary_email = true
log_to_file = true
summary_email_to = "ops@example.com"
summary_email_from_account = "client-mailbox@example.com"
  [accounts.triage_overrides.priority_read_state]
  "Priority 1" = false
  "Priority 2" = true   # Example: auto-mark P2 as read for this account
